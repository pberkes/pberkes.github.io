
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">

<html>

<HEAD>
<META HTTP-EQUIV="Content-Type" CONTENT="text/html; CHARSET=iso-8859-1">
<META http-equiv="Content-Style-Type" content="text/css">
<TITLE>Dbn_Tutorial</TITLE>
<META NAME="Author" CONTENT="Pietro Berkes">
<META NAME="Keywords" CONTENT="">
<META NAME="Description" CONTENT="">
<LINK REL=STYLESHEET TYPE="text/css" HREF="https://pberkes.github.io/stylesheet/main_styles.css" TITLE="Main Styles">

<script language="javascript" type="text/javascript">
var timeout	= 500;
var closetimer	= 0;
var ddmenuitem	= 0;

// open hidden layer
function mopen(id)
{	
	// cancel close timer
	mcancelclosetime();

	// close old layer
	if(ddmenuitem) ddmenuitem.style.visibility = 'hidden';

	// get new layer and show it
	ddmenuitem = document.getElementById(id);
	ddmenuitem.style.visibility = 'visible';

}
// close showed layer
function mclose()
{
	if(ddmenuitem) ddmenuitem.style.visibility = 'hidden';
}

// go close timer
function mclosetime()
{
	closetimer = window.setTimeout(mclose, timeout);
}

// cancel close timer
function mcancelclosetime()
{
	if(closetimer)
	{
		window.clearTimeout(closetimer);
		closetimer = null;
	}
}

// close layer when click-out
document.onclick = mclose;
</script>
</HEAD>

<body>
<DIV class="header">

<ul id="ddmenu">
  <li>
    <A HREF="https://pberkes.github.io/index.html">home</A>
  </li>
  <li>
    <A HREF="https://pberkes.github.io/publications.html">publications</A>
  </li>
  <li>
    <A HREF="https://pberkes.github.io/software.html">software</A>
  </li>
  <li>
    <A HREF="#" onmouseover="mopen('mlinks')" 
        onmouseout="mclosetime()">links &#9662;</a>
        <div id="mlinks" 
            onmouseover="mcancelclosetime()" 
            onmouseout="mclosetime()">
        <a href="https://github.com/pberkes">Github</a>
        <a href="https://www.linkedin.com/in/pietroberkes/">LinkedIn</a>
        <a
  href="https://scholar.google.ch/citations?user=Xbh1cHoAAAAJ">Google Scholar</a>
        <a href="http://www.masterbaboon.com">masterbaboon.com</a>
        </div>
  </li>
</ul>
</DIV>

<div style="clear:both"></div>

<div class='content'>
<H2>Tutorial on energy models and Deep Belief Networks</H2>

<P>
<b>Topics:</b> Energy models, causal generative models vs. energy models in overcomplete ICA, contrastive divergence learning, score matching, restricted Boltzmann machines, deep belief networks

<P>
<b>Presentation notes:</b> <a href="http://www.gatsby.ucl.ac.uk/~berkes/data/presentations/dbn_tutorial_notes_10_08_2007.pdf">.pdf<a><BR>
This is a scan of my notes for the tutorial. I'm afraid they're not very
polished... The first part on ICA is missing, but you can have a look at
<a href="http://www.gatsby.ucl.ac.uk/~turner/energy%20models/enmodels.html">Rich's notes</a> that refer to the same paper.

<P>
<b>Task for the coding session:</b> Implementing a deep belief network for handwritten
letters classification and generation.

<P>
Worksheet <a href="http://www.gatsby.ucl.ac.uk/~berkes/data/presentations/dbn_tutorial_worksheet_10_08_2007.odp">.odp</a>,
<a href="http://www.gatsby.ucl.ac.uk/~berkes/data/presentations/dbn_tutorial_worksheet_10_08_2007.pdf">.pdf</a>

<P>
Data: Begin using only a few letters from the Binary Alphadigits. This dataset
is quite small, so that learning is fast and the hidden layers only need about 100
units each to reach a good perfomance. Test the complete system on
the MNIST database (split the data into mini-batches).<BR>

You'll find a copy of the Binary Alphadigits and MNIST databases at
<a href="http://www.cs.toronto.edu/~roweis/data.html">Sam Roweis'</a> site.

<P>
My solution: <a href="http://www.gatsby.ucl.ac.uk/~berkes/data/software/various/pietro_dbn_submission.tgz">.tgz</a> (in python)

<P>
<b>Essential bibliography:</b>

<ul>
<li>Hinton, G., Welling, M., Teh, Y. and Osindero, S. A new view of
             ICA. Proceedings of ICA-2001. 2001.

<li>Hinton, G. Training products of experts by minimizing contrastive
             divergence. Neural Computation, 14(8), 2002.

<li>Teh, Y., Welling, M., Osindero, S. and Hinton, G. Energy-based
             models for sparse overcomplete representations. Journal of
             Machine Learning Research, 4:1235-1260, 2003.

<li>Carreira-Perpignan, M. and Hinton, G. On contrastive divergence
             learning. In R. C. adn Z. Gaharamani, editor, Artificial
             intelligence and statistics, pages 33-41. Fort Lauderdale, 2005.
             Society for Artificial Intelligence and Statistics.

<li>Hyvarinen, A. Estimation of non-normalized statistical models
             using score matching. Journal of Machine Learning Research,
             6:695-709, 2005.

<li>Hinton, G., Osindero, S. and Teh, Y. A fast learning algorithm
             for deep belief nets. Neural Computation, 18(4):1527-1554, 2006.

<li>Hinton, G. and Salakhutdinov, R. Reducing the dimensionality of
             data with neural networks. Science, 313(5786):504-507, 2006.

<li>Hyvarinen, A. Some extensions of score matching. Computational
             Statistics & Data Analysis, 51(5):2499-2512, 2006.

</ul>
</div>

</body>
</html>
